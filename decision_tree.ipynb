{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXC = 'EXC'\n",
    "MSG = 'MSG'\n",
    "\n",
    "LEVEL_THRESHOLD_MAPPING = {EXC: 0.5, \n",
    "                           MSG: 0.5}\n",
    "PRIORITIES  = [EXC, MSG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HierarchyClustering(object):\n",
    "    def __init__(self, name_featmat_mapping):\n",
    "        self.route_clusters_mapping = {}\n",
    "        self.route_level_mapping = {}\n",
    "        self.filter_featmat_mapping = {PRIORITIES[i]: name_featmat_mapping[i] for i in range(len(PRIORITIES))}\n",
    "        self.filter_threshold_mapping = LEVEL_THRESHOLD_MAPPING\n",
    "        \n",
    "    def fit(self):\n",
    "        self.traverse()\n",
    "        self.create_utility_mapping()\n",
    "        self.calculate_CDF()\n",
    "        \n",
    "    def traverse(self):\n",
    "# =============================================================================\n",
    "#         Traverse the whole branches\n",
    "# =============================================================================\n",
    "        level = 0\n",
    "        root_mat = self.filter_featmat_mapping[PRIORITIES[level]]\n",
    "        doc_ids = [doc_id for doc_id in range(root_mat.shape[0])]\n",
    "        idxmat_docid_mapping = dict(zip(doc_ids, doc_ids))\n",
    "        docid_idxmat_mapping = idxmat_docid_mapping.copy()\n",
    "        clusterid_docids_mapping = self.run_cluster(self.filter_featmat_mapping[PRIORITIES[level]], self.filter_threshold_mapping[PRIORITIES[level]], idxmat_docid_mapping, docid_idxmat_mapping)\n",
    "        self.traverse_tree_structure_by_recursion(str(level), level, idxmat_docid_mapping, clusterid_docids_mapping)\n",
    "    \n",
    "    def create_utility_mapping(self):\n",
    "# =============================================================================\n",
    "#         # Route - Level map\n",
    "# =============================================================================\n",
    "        self.route_level_mapping = {}\n",
    "        for idx, (route, clusters) in enumerate(self.route_clusters_mapping.items()):\n",
    "            if idx == 0:\n",
    "                self.route_level_mapping[route] = 0\n",
    "            for idx, clusterid in enumerate(clusters):\n",
    "                child_route = route + '->' + str(idx)\n",
    "                self.route_level_mapping[child_route] = child_route.count('->')\n",
    "                \n",
    "        # Level - Routes Map\n",
    "        self.level_routes_mapping = {}\n",
    "        for route, level in self.route_level_mapping.items():\n",
    "            self.level_routes_mapping[level] = self.level_routes_mapping.get(level, []) + [route]\n",
    "            \n",
    "    def build_submatrix(self, docids, feature_matrix):\n",
    "# =============================================================================\n",
    "#         Build submatrix\n",
    "# =============================================================================\n",
    "        mat_size = len(docids)\n",
    "        idxmat_docid_mapping = dict(zip(range(mat_size), docids))\n",
    "        docid_idxmat_mapping = dict(zip(docids, range(mat_size)))\n",
    "        submatrix = np.zeros((mat_size, mat_size))\n",
    "        for i in range(mat_size):\n",
    "            for j in range(i, mat_size):\n",
    "                submatrix[i][j] = feature_matrix[idxmat_docid_mapping[i]][idxmat_docid_mapping[j]]\n",
    "                submatrix[j][i] = feature_matrix[idxmat_docid_mapping[j]][idxmat_docid_mapping[i]]\n",
    "        return submatrix, idxmat_docid_mapping, docid_idxmat_mapping\n",
    "    \n",
    "    def traverse_tree_structure_by_recursion(self, route, level, idxmat_docid_mapping, clusterid_docids_mapping):\n",
    "# =============================================================================\n",
    "#         Traverse tree structure by using recursion\n",
    "# =============================================================================\n",
    "        self.route_clusters_mapping[route] = list(clusterid_docids_mapping.values())\n",
    "        self.route_level_mapping[route] = level\n",
    "        if level < len(PRIORITIES) - 1 :\n",
    "            for idx, (cluster, docids) in enumerate(clusterid_docids_mapping.items()):\n",
    "                submatrix, r_idxmat_docid_mapping, r_docid_idxmat_mapping = self.build_submatrix(docids, self.filter_featmat_mapping[PRIORITIES[level + 1]])\n",
    "                r_clusterid_docids_mapping = self.run_cluster(submatrix, self.filter_threshold_mapping[PRIORITIES[level + 1]], r_idxmat_docid_mapping, r_docid_idxmat_mapping)\n",
    "                route = route + '->' + str(idx)\n",
    "                self.traverse_tree_structure_by_recursion(route, level+1, r_idxmat_docid_mapping, r_clusterid_docids_mapping)\n",
    "                route = route[:route.rfind('->')]\n",
    "        else:\n",
    "            for i, sublist in enumerate(list(clusterid_docids_mapping.values())):\n",
    "                route = route + '->' +str(i)\n",
    "                self.route_clusters_mapping[route] =[[i for i in sublist]]\n",
    "                route = route[:route.rfind('->')]\n",
    "                \n",
    "    def run_cluster(self, feature_matrix, threshold, idxmat_docid_mapping, docid_idxmat_mapping):\n",
    "# =============================================================================\n",
    "#         Cluster\n",
    "# =============================================================================\n",
    "        \n",
    "        def order_subclusters(clusterid_docids_mapping):\n",
    "# =============================================================================\n",
    "#             Order\n",
    "# =============================================================================\n",
    "            \n",
    "            if len(clusterid_docids_mapping.keys()) > 1:\n",
    "                clusterids = list(clusterid_docids_mapping.keys())\n",
    "                clusterid_numelements_mapping = {clusterid: len(docids) for clusterid, docids in clusterid_docids_mapping.items()}\n",
    "                cluster_most_docid = sorted(clusterid_numelements_mapping.items(), key=lambda x:x[1], reverse=True)[0][0]\n",
    "                \n",
    "                # Initial step: by default I take the pivot pointing to the index 0, while clusterid_most_docid is moved to index 0\n",
    "                stacked_clusterids = clusterids.copy()\n",
    "                stacked_clusterids.remove(cluster_most_docid)\n",
    "                stacked_clusterids.insert(0, cluster_most_docid)\n",
    "                \n",
    "                pivot_index = 0\n",
    "                while pivot_index < len(clusterids):\n",
    "                    # Updating pivot pointing to the next cluster after reordering clusterid which has similarity score \n",
    "                    # in decending order. \n",
    "                    pivot = stacked_clusterids[pivot_index]\n",
    "                    rep_docid_of_pivot_cluster = clusterid_docids_mapping[pivot][0]       #choose the first docid to be represented information of that clusterid\n",
    "                    sub_list = stacked_clusterids[pivot_index + 1:]                       #take the left elements to compare \n",
    "                    if len(sub_list) > 0:\n",
    "                        max_score = -1\n",
    "                        max_index = 0\n",
    "                        for idx, clusterid in enumerate(sub_list):\n",
    "                            rep_docid_of_cluster_x = clusterid_docids_mapping[clusterid][0]\n",
    "                            similarity_of_2_clusters = feature_matrix[docid_idxmat_mapping[rep_docid_of_pivot_cluster]][docid_idxmat_mapping[rep_docid_of_cluster_x]]\n",
    "                            if max_score < similarity_of_2_clusters:\n",
    "                                max_score = similarity_of_2_clusters\n",
    "                                max_index = idx\n",
    "    \n",
    "                        next_pivot = sub_list[max_index]\n",
    "                        stacked_clusterids.remove(next_pivot)\n",
    "                        stacked_clusterids.insert(0, next_pivot)\n",
    "                    else:\n",
    "                        last_element = stacked_clusterids.pop()\n",
    "                        stacked_clusterids.insert(0, last_element)\n",
    "                    pivot_index += 1\n",
    "                \n",
    "                clusterid_neworder_mapping = {ordered_clusterid: idx for idx, ordered_clusterid in enumerate(stacked_clusterids)}\n",
    "                clusterid_docids_mapping = {k: clusterid_docids_mapping[v] for k, v in clusterid_neworder_mapping.items()}\n",
    "                clusterid_docids_mapping = dict(collections.OrderedDict(sorted(clusterid_docids_mapping.items(), key=lambda x:x[0])))\n",
    "            return clusterid_docids_mapping\n",
    "                \n",
    "        \n",
    "        docid_idxmat_mapping = dict(zip(idxmat_docid_mapping.values(), idxmat_docid_mapping.keys()))\n",
    "        doc_ids = list(idxmat_docid_mapping.values())\n",
    "        clusterid = 0\n",
    "        clusterid_docids_mapping = {}\n",
    "        while len(doc_ids) > 0:\n",
    "            pivot = doc_ids[0]\n",
    "            sub = [doc_id for doc_id in doc_ids if doc_id != pivot]\n",
    "            clusterid_docids_mapping[clusterid] = [pivot]\n",
    "            doc_ids.remove(pivot)\n",
    "            for doc_id in sub:\n",
    "                if feature_matrix[docid_idxmat_mapping[pivot]][docid_idxmat_mapping[doc_id]] >= threshold:\n",
    "                    clusterid_docids_mapping[clusterid].append(doc_id)\n",
    "                    doc_ids.remove(doc_id)\n",
    "            clusterid += 1\n",
    "        clusterid_docids_mapping = order_subclusters(clusterid_docids_mapping)\n",
    "        return clusterid_docids_mapping\n",
    "\n",
    "    def export_graphviz(self, graphviz_path):\n",
    "# =============================================================================\n",
    "#          Draw tree graph by Graphviz\n",
    "#          Example input: os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Users\\\\quanthuynh\\\\temp\\\\graphviz-2.38\\\\release\\\\bin\\\\'\n",
    "# =============================================================================\n",
    "        \n",
    "        depth = 1\n",
    "        try:\n",
    "            os.environ[\"PATH\"] += os.pathsep + graphviz_path\n",
    "            from graphviz import Digraph\n",
    "            dot = Digraph(comment='Hierarchy Tree Structure Clustering')\n",
    "            \n",
    "            for level, routes in self.level_routes_mapping.items():\n",
    "                if level <= depth + 1 and level != 0:\n",
    "                    for route in routes:\n",
    "                        node_label = PRIORITIES[level - 1] + ' ' + route[route.rfind('->') + 2:]\n",
    "                        dot.node(route, node_label)\n",
    "                            \n",
    "            for level, routes in self.level_routes_mapping.items():\n",
    "                if level <= depth and level < len(PRIORITIES):\n",
    "                    if level == 0:\n",
    "                        for child_route in self.level_routes_mapping[level + 1]:\n",
    "                            dot.edge('root', child_route)\n",
    "                    else:\n",
    "                        for route in routes:\n",
    "                            children_routes = [route + '->' + str(i) for i in self.route_clusters_mapping[route].keys()]\n",
    "                            for child_route in children_routes:\n",
    "                                dot.edge(route, child_route)\n",
    "            dot.render('graphviz/tree-structure.gv', view=True)\n",
    "        except:\n",
    "            # Cannot import graphviz\n",
    "            pass\n",
    "    \n",
    "    def calculate_CDF(self):\n",
    "        self.level_CDF_mapping = {}\n",
    "        for level_threshold in range(len(PRIORITIES) + 1):\n",
    "            route_elements_mapping = {route: sum(len(errorids) for errorids in clusters) for route, clusters in self.route_clusters_mapping.items() if self.route_level_mapping[route]==level_threshold}\n",
    "            route_elements_mapping = collections.OrderedDict({route: elements for route, elements in sorted(route_elements_mapping.items(), key=lambda x: x[1])})\n",
    "            CDF = HierarchyClustering.get_CDF(route_elements_mapping)\n",
    "            colors = HierarchyClustering.get_color_based_occurrence_ratio(route_elements_mapping)\n",
    "            self.route_docids_mapping = {route: [item for sublist in self.route_clusters_mapping[route] for item in sublist] for route in route_elements_mapping.keys() if self.route_level_mapping[route]==level_threshold}\n",
    "            self.level_CDF_mapping[level_threshold] = (self.route_docids_mapping, colors, CDF)\n",
    "        return self.level_CDF_mapping \n",
    "            \n",
    "    def plot_CDF(self, level_threshold):\n",
    "        route_elements_mapping = {route: sum(len(errorids) for errorids in clusters.values()) for route, clusters in self.route_clusters_mapping.items() if self.route_level_mapping[route]==level_threshold}\n",
    "        HierarchyClustering.plot_cluster_topic_histogram(route_elements_mapping)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_info_of_cluster_id(cluster_id, cluster_dict, cumulative_pro_func):\n",
    "        total = sum(cluster_dict.values())\n",
    "        percent = int(cluster_dict[cluster_id] / total * 100 )\n",
    "        cum_per = cumulative_pro_func[cluster_id]\n",
    "        text = 'ID {}\\n{}%'.format(cluster_id, percent, cum_per)\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def get_CDF(route_elements_mapping):\n",
    "        CDF = {}\n",
    "        account = 0\n",
    "        total = sum(route_elements_mapping.values())\n",
    "        for clusterid, numelements in route_elements_mapping.items():\n",
    "            CDF[clusterid] = int((account + numelements) / total * 100)\n",
    "            account = account + numelements\n",
    "        return CDF\n",
    "\n",
    "    @staticmethod\n",
    "    def get_color_based_occurrence_ratio(route_elements_mapping):\n",
    "        color_range = [10,20,70]\n",
    "        color = []\n",
    "        for k, v in route_elements_mapping.items():\n",
    "            if v < color_range[0]:\n",
    "                color.append('red')\n",
    "            elif v > color_range[1]:\n",
    "                color.append('lightgreen')\n",
    "            else:\n",
    "                color.append('yellow')\n",
    "        return color\n",
    "        \n",
    "    @staticmethod\n",
    "    def plot_cluster_topic_histogram(utility_dictionary):\n",
    "        keys = utility_dictionary.keys()\n",
    "        values = utility_dictionary.values()\n",
    "        cluster_dict = dict(zip(keys, values))\n",
    "        cluster_dict = {k: v for k, v in sorted(cluster_dict.items(), key=lambda x: x[1])}\n",
    "        cumulative_pro_func = HierarchyClustering.get_CDF(cluster_dict)\n",
    "        keys = [HierarchyClustering.get_info_of_cluster_id(x, cluster_dict, cumulative_pro_func) for x in cluster_dict.keys()]\n",
    "        values = list(cluster_dict.values())\n",
    "        color = HierarchyClustering.get_color_based_occurrence_ratio(cumulative_pro_func)\n",
    "    \n",
    "        # Plot \n",
    "        fig=plt.figure(figsize=(20, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.bar(keys, values, color = color)\n",
    "        plt.title('Failed Execution Test Result (document) distribution per Topic Clustering')\n",
    "        plt.xlabel('rare <---------------------------------------------> usual', fontsize=12)\n",
    "        plt.ylabel('Number of failed execution test result', fontsize=12)\n",
    "        ax1.grid(True)\n",
    "    \n",
    "        # Plot step function for cumulative probablity distribution function\n",
    "        ax2 = ax1.twinx()\n",
    "        x_step = [i for i in range(len(keys))]\n",
    "        y_step = [v for k, v in cumulative_pro_func.items()]\n",
    "        ax2.plot(x_step, y_step, color = 'b')\n",
    "        ax2.set_ylabel('Accumulative percentage',fontsize=12)\n",
    "    \n",
    "        # Plot annotation in the diagram\n",
    "        annotations = [str(cumulative_pro_func[x]) for x in cluster_dict]\n",
    "        for i, txt in enumerate(annotations):\n",
    "            plt.annotate(txt, (x_step[i], y_step[i]))\n",
    "        plt.show()\n",
    "        return cluster_dict, color, cumulative_pro_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
